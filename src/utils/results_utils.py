import datetime
import hashlib
import os
from concurrent.futures import ThreadPoolExecutor
from typing import List

from loguru import logger


class ResultsUtils:
    def __init__(self):
        pass

    def parse_llm_outputs(
        self,
        prompts_without_special_tokens: List[str],
        llm_outputs_without_special_tokens: List[str],
    ):
        """
        Generates a new list containing only the new output generated by the LLM.
        In general LLM outputs contain both the input prompt and the generated output.
        This function takes the input prompts and the complete output generated by
        the model and parses out the newly generated text by the model.
        """
        if len(prompts_without_special_tokens) != len(llm_outputs_without_special_tokens):
            raise AssertionError("Each prompt should have a corresponding LLM generated output")

        generated_abstracts_map = map(
            lambda prompt, output: output[len(prompt) :].strip(),
            prompts_without_special_tokens,
            llm_outputs_without_special_tokens,
        )

        return list(generated_abstracts_map)


class TestResultsUtils(ResultsUtils):
    def __init__(self, max_thread_pool_workers: int, result_dir: str):
        super().__init__()
        self.verify_result_dir(result_dir)
        self.result_dir = result_dir
        self.thread_pool_executor = ThreadPoolExecutor(max_workers=max_thread_pool_workers)

    def verify_result_dir(self, result_dir: str):
        result_dir_path = result_dir if os.path.isabs(result_dir) else os.path.join(os.getcwd(), result_dir)
        if not os.path.exists(result_dir_path):
            logger.info(f"Test results directory {result_dir_path} does not exist. Creating directory...")
            os.makedirs(result_dir_path, exist_ok=True)
            logger.success(f"Test results directory created at {result_dir_path}.")

        if not os.path.isdir(result_dir_path):
            raise NotADirectoryError(f"Path {result_dir_path} is not a directory. Please provide a directory path.")

    def save_result(self, article: str, abstract: str) -> None:
        h = hashlib.md5(usedforsecurity=False)
        h.update(article.encode(encoding="utf-8"))
        article_hash = h.hexdigest()
        current_time = datetime.datetime.now()

        # `:` cannot be part of a valid file name in NTFS, as it is used as a delimeter for multiple files.
        # Refer https://stackoverflow.com/questions/54508733/python-3-not-raising-exception-for-invalid-file-name
        time_str = str(current_time).replace(":", "-").replace(" ", "_")

        article_filename = f"{time_str}_{article_hash}_article.txt"
        abstract_filename = f"{time_str}_{article_hash}_abstract.txt"
        try:
            with open(os.path.join(self.result_dir, article_filename), "w", encoding="utf-8") as article_file:
                article_file.write(article)
        except IOError as e:
            logger.error(f"ERRNO {e.errno}. {e.strerror}. Could not write ARTICLE file with hash {article_hash}")

        try:
            with open(os.path.join(self.result_dir, abstract_filename), "w", encoding="utf-8") as abstract_file:
                abstract_file.write(abstract)
        except IOError as e:
            logger.error(f"ERRNO {e.errno}. {e.strerror}. Could not write ABSTRACT file with hash {article_hash}")

    def save_result_list(self, articles: List[str], generated_abstracts: List[str]):
        for article, abstract in zip(articles, generated_abstracts):
            self.thread_pool_executor.submit(self.save_result, article, abstract)

    def parse_and_save(
        self,
        articles: List[str],
        prompts_without_special_tokens: List[str],
        llm_outputs_without_special_tokens: List[str],
    ):
        generated_abstracts = self.parse_llm_outputs(
            prompts_without_special_tokens,
            llm_outputs_without_special_tokens,
        )
        self.save_result_list(articles, generated_abstracts)

    def shutdown(self, wait: bool, cancel_futures: bool):
        self.thread_pool_executor.shutdown(wait=wait, cancel_futures=cancel_futures)
