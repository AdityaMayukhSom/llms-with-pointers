import base64
import hashlib
import os
import re
from typing import List


def extract_user_message(text: str) -> str:
    pattern = r"<\|start_header_id\|>user<\|end_header_id\|>(.*?)<\|eot_id\|>"
    match = re.search(pattern, text, re.DOTALL)
    if match:
        return match.group(1).strip()
    return ""


def parse_llm_outputs(
    prompts_without_special_tokens: List[str],
    llm_outputs_without_special_tokens: List[str],
):
    """
    Generates a new list containing only the new output generated by the LLM.
    In general LLM outputs contain both the input prompt and the generated output.
    This function takes the input prompts and the complete output generated by
    the model and parses out the newly generated text by the model.
    """
    if len(prompts_without_special_tokens) != len(llm_outputs_without_special_tokens):
        raise AssertionError("Each prompt should have a corresponding LLM generated output")

    generated_abstracts_map = map(
        lambda prompt, output: output[len(prompt) :].strip(),
        prompts_without_special_tokens,
        llm_outputs_without_special_tokens,
    )

    return list(generated_abstracts_map)


def save_test_results(articles: List[str], generated_abstracts: List[str], result_dir: str):
    for article, abstract in zip(articles, generated_abstracts):
        h = hashlib.sha256(usedforsecurity=False)
        h.update(article.encode(encoding="utf-8"))
        file_hash = base64.b64decode(h.hexdigest())

        article_filename = "{}_article.txt".format(file_hash)
        abstract_filename = "{}_abstract.txt".format(file_hash)

        with open(os.path.join(result_dir, article_filename), "w") as article_file:
            article_file.write(article)

        with open(os.path.join(result_dir, abstract_filename), "w") as abstract_file:
            abstract_file.write(abstract)
